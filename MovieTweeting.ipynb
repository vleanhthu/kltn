{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862b118f",
   "metadata": {},
   "source": [
    "DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c99e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from textblob) (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>=3.9->textblob) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>=3.9->textblob) (2025.10.23)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ====== 0. IMPORT & CONFIG ======\n",
    "!pip install textblob\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "DATA_DIR = \"C:\\\\Users\\\\ADMIN\\\\Documents\\\\Kh√≥a lu·∫≠n\\\\MovieTweetings Dataset\"      # th∆∞ m·ª•c ch·ª©a ratings.dat & movies.dat\n",
    "MIN_USER_INTERACTIONS = 5  # user c√≥ < 5 rating: b·ªè qua test\n",
    "CV_FOLDS = 3               # s·ªë fold Temporal Cross-Validation\n",
    "TRAIN_RATIOS = [0.7, 0.75, 0.8]  # t·ªâ l·ªá train/test cho t·ª´ng fold\n",
    "\n",
    "def sec(title): \n",
    "    print(\"\\n\" + \"=\"*12 + f\" {title.upper()} \" + \"=\"*12)\n",
    "#ƒê√¢y l√† h√†m ti·ªán √≠ch ƒë·ªÉ in ra ti√™u ƒë·ªÅ m·ªói b∆∞·ªõc trong console cho d·ªÖ nh√¨n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f59b844",
   "metadata": {},
   "source": [
    "- Fold 1: 70% train, 30% test\n",
    "- Fold 2: 75% train, 25% test\n",
    "- Fold 3: 80% train, 20% test \n",
    "\n",
    "üîπ M·ª•c ti√™u: ki·ªÉm tra xem m√¥ h√¨nh ·ªïn ƒë·ªãnh th·∫ø n√†o khi l∆∞·ª£ng d·ªØ li·ªáu train thay ƒë·ªïi theo th·ªùi gian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18092a71",
   "metadata": {},
   "source": [
    "ƒê·ªÉ ƒë√°nh gi√° t√≠nh ·ªïn ƒë·ªãnh c·ªßa m√¥ h√¨nh trong ƒëi·ªÅu ki·ªán th·ªùi gian th·ª±c, kh√≥a lu·∫≠n s·ª≠ d·ª•ng Temporal Cross-Validation v·ªõi 3 t·ªâ l·ªá chia d·ªØ li·ªáu: 70/30, 75/25 v√† 80/20.\n",
    "\n",
    "Ba t·ªâ l·ªá n√†y l·∫ßn l∆∞·ª£t m√¥ ph·ªèng c√°c giai ƒëo·∫°n kh√°c nhau trong v√≤ng ƒë·ªùi c·ªßa h·ªá th·ªëng g·ª£i √Ω:\n",
    "\n",
    "- Khi h·ªá th·ªëng m·ªõi kh·ªüi t·∫°o (√≠t d·ªØ li·ªáu qu√° kh·ª© ‚Äì Fold 1).\n",
    "\n",
    "- Khi h·ªá th·ªëng d·∫ßn t√≠ch l≈©y th√™m d·ªØ li·ªáu (Fold 2).\n",
    "\n",
    "- Khi h·ªá th·ªëng ƒë√£ v·∫≠n h√†nh ·ªïn ƒë·ªãnh v·ªõi l∆∞·ª£ng d·ªØ li·ªáu l·ªõn (Fold 3).\n",
    "\n",
    "C√°ch chia n√†y ƒë·∫£m b·∫£o v·ª´a t√¥n tr·ªçng t√≠nh th·ªùi gian c·ªßa d·ªØ li·ªáu, v·ª´a ƒë√°nh gi√° ƒë∆∞·ª£c kh·∫£ nƒÉng h·ªçc v√† t·ªïng qu√°t h√≥a c·ªßa m√¥ h√¨nh khi l∆∞·ª£ng d·ªØ li·ªáu hu·∫•n luy·ªán thay ƒë·ªïi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcbb7ac",
   "metadata": {},
   "source": [
    "MIN_USER_INTERACTIONS = 5\n",
    "\n",
    "- M·ªôt s·ªë user ch·ªâ c√≥ v√†i rating (1‚Äì2 phim), n·∫øu chia 80/20 th√¨ test r·ªóng (v√¨ 20% c·ªßa 2 d√≤ng = 0.4).\n",
    "\n",
    "- Cho n√™n: n·∫øu user c√≥ √≠t h∆°n 5 rating, ta cho h·∫øt v√†o train, kh√¥ng chia test.\n",
    "\n",
    "- Tr√°nh l·ªói khi m√¥ h√¨nh h·ªçc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43398649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ LOAD D·ªÆ LI·ªÜU ============\n",
      "ratings: (921398, 4) | movies: (38018, 3)\n"
     ]
    }
   ],
   "source": [
    "sec(\"LOAD D·ªÆ LI·ªÜU\")\n",
    "\n",
    "def read_dat(fname, cols):\n",
    "    path = os.path.join(DATA_DIR, fname) #Gh√©p th∆∞ m·ª•c g·ªëc (DATA_DIR) v·ªõi t√™n file (fname) ‚Üí t·∫°o ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß.\n",
    "    if not os.path.exists(path): #Ki·ªÉm tra file c√≥ t·ªìn t·∫°i kh√¥ng.\n",
    "        raise FileNotFoundError(f\"Kh√¥ng t√¨m th·∫•y file: {path}\")\n",
    "    for enc in (\"utf-8\", \"latin-1\", \"cp1252\"):\n",
    "        try:\n",
    "            return pd.read_csv(path, sep=\"::\", engine=\"python\", names=cols, encoding=enc)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    return pd.read_csv(path, sep=\"::\", engine=\"python\", names=cols, encoding=\"latin-1\", on_bad_lines=\"skip\")\n",
    "#ƒê·ªçc file .dat b·∫±ng pandas.sep=\"::\": v√¨ file MovieTweetings kh√¥ng ph·∫£i CSV th√¥ng th∆∞·ªùng (d·∫•u ph·∫©y ,) m√† d√πng :: l√†m d·∫•u ph√¢n c√°ch.\n",
    "\n",
    "#H√†m read_dat() tr·∫£ v·ªÅ m·ªôt DataFrame s·∫°ch, c√≥ t√™n c·ªôt ƒë√∫ng, kh√¥ng l·ªói m√£ h√≥a.\n",
    "ratings = read_dat(\"ratings.dat\", [\"UserID\",\"MovieID\",\"Rating\",\"Timestamp\"])\n",
    "movies  = read_dat(\"movies.dat\",  [\"MovieID\",\"Title\",\"Genres\"])\n",
    "\n",
    "print(\"ratings:\", ratings.shape, \"| movies:\", movies.shape)\n",
    "\n",
    "ratings[\"Datetime\"] = pd.to_datetime(ratings[\"Timestamp\"], unit=\"s\", errors=\"coerce\")\n",
    "ratings = ratings.astype({\"UserID\":\"int32\",\"MovieID\":\"int32\",\"Rating\":\"int16\",\"Timestamp\":\"int64\"})\n",
    "movies[\"MovieID\"] = movies[\"MovieID\"].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74453128",
   "metadata": {},
   "source": [
    "B·∫£ng ratings: 921 398 b·∫£n ghi v√† 4 thu·ªôc t√≠nh (UserID, MovieID, Rating, Timestamp). M·ªói b·∫£n ghi bi·ªÉu di·ªÖn m·ªôt l∆∞·ª£t ƒë√°nh gi√° m√† ng∆∞·ªùi d√πng d√†nh cho m·ªôt b·ªô phim c·ª• th·ªÉ t·∫°i th·ªùi ƒëi·ªÉm x√°c ƒë·ªãnh.\n",
    "\n",
    "B·∫£ng movies: 38 018 b·∫£n ghi v√† 3 thu·ªôc t√≠nh (MovieID, Title, Genres). M·ªói d√≤ng t∆∞∆°ng ·ª©ng v·ªõi m·ªôt b·ªô phim duy nh·∫•t k√®m ti√™u ƒë·ªÅ v√† danh s√°ch th·ªÉ lo·∫°i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01b717a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ HI·ªÇU D·ªÆ LI·ªÜU ============\n",
      "S·ªë user: 71707 | S·ªë movie: 38013 | T·ªïng rating: 921398\n",
      "Kho·∫£ng th·ªùi gian rating: 2013-02-28 14:38:27 ‚Üí 2021-11-24 05:41:29\n",
      "\n",
      "Ph√¢n ph·ªëi rating (0‚Äì10):\n",
      "Rating\n",
      "0        281\n",
      "1      10814\n",
      "2       9223\n",
      "3      15487\n",
      "4      28193\n",
      "5      69747\n",
      "6     120370\n",
      "7     206680\n",
      "8     222146\n",
      "9     130106\n",
      "10    108351\n",
      "Name: count, dtype: int64\n",
      "\n",
      "M√¥ t·∫£ th·ªëng k√™ rating:\n",
      "              Rating\n",
      "count  921398.000000\n",
      "mean        7.312627\n",
      "std         1.852559\n",
      "min         0.000000\n",
      "25%         6.000000\n",
      "50%         7.000000\n",
      "75%         9.000000\n",
      "max        10.000000\n"
     ]
    }
   ],
   "source": [
    "sec(\"HI·ªÇU D·ªÆ LI·ªÜU\")\n",
    "\n",
    "print(\"S·ªë user:\", ratings[\"UserID\"].nunique(),\n",
    "      \"| S·ªë movie:\", ratings[\"MovieID\"].nunique(),\n",
    "      \"| T·ªïng rating:\", len(ratings))\n",
    "\n",
    "print(\"Kho·∫£ng th·ªùi gian rating:\", ratings[\"Datetime\"].min(), \"‚Üí\", ratings[\"Datetime\"].max())\n",
    "\n",
    "print(\"\\nPh√¢n ph·ªëi rating (0‚Äì10):\")\n",
    "print(ratings[\"Rating\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nM√¥ t·∫£ th·ªëng k√™ rating:\")\n",
    "print(ratings[[\"Rating\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd38ac",
   "metadata": {},
   "source": [
    "√ù nghƒ©a:\n",
    "- C·ªôt ‚ÄúRating‚Äù l√† ƒëi·ªÉm ng∆∞·ªùi d√πng ch·∫•m cho phim, t·ª´ 0 ƒë·∫øn 10.\n",
    "- B·∫£ng n√†y ƒë·∫øm t·∫ßn su·∫•t (s·ªë l∆∞·ª£t) c·ªßa t·ª´ng ƒëi·ªÉm s·ªë.\n",
    "\n",
    "‚Üí D·ªØ li·ªáu thi√™n l·ªách v·ªÅ ph√≠a cao (positive bias), t·ª©c l√† ph·∫ßn l·ªõn ng∆∞·ªùi d√πng ƒë√°nh gi√° phim h·ªç th√≠ch.\n",
    "\n",
    "‚Üí Khi hu·∫•n luy·ªán m√¥ h√¨nh, c·∫ßn l∆∞u √Ω ƒëi·ªÅu n√†y (c√≥ th·ªÉ d√πng normalization ho·∫∑c implicit feedback modeling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c92cf3",
   "metadata": {},
   "source": [
    "B·ªô d·ªØ li·ªáu MovieTweetings ch·ª©a 921 398 l∆∞·ª£t ƒë√°nh gi√° t·ª´ 71 707 ng∆∞·ªùi d√πng cho 38 013 b·ªô phim, ƒë∆∞·ª£c thu th·∫≠p trong giai ƒëo·∫°n 2013 ‚Äì 2021.\n",
    "\n",
    "Ph√¢n ph·ªëi ƒëi·ªÉm ƒë√°nh gi√° cho th·∫•y ph·∫ßn l·ªõn ng∆∞·ªùi d√πng ch·∫•m ƒëi·ªÉm cao (tr√™n 7), v·ªõi ƒëi·ªÉm trung b√¨nh l√† 7.31 v√† ƒë·ªô l·ªách chu·∫©n 1.85.\n",
    "ƒêi·ªÅu n√†y ph·∫£n √°nh hi·ªán t∆∞·ª£ng thi√™n l·ªách t√≠ch c·ª±c (positive bias) th∆∞·ªùng g·∫∑p trong c√°c b·ªô d·ªØ li·ªáu g·ª£i √Ω, khi ng∆∞·ªùi d√πng c√≥ xu h∆∞·ªõng ch·ªâ ƒë√°nh gi√° nh·ªØng phim h·ªç y√™u th√≠ch.\n",
    "\n",
    "D·ªØ li·ªáu n√†y bao ph·ªß giai ƒëo·∫°n d√†i v√† ƒë·ªß l·ªõn ƒë·ªÉ th·ª±c hi·ªán c√°c th√≠ nghi·ªám v·ªõi m√¥ h√¨nh Collaborative Filtering, Content-Based, v√† Hybrid, c≈©ng nh∆∞ √°p d·ª•ng chia d·ªØ li·ªáu theo th·ªùi gian (Temporal Cross-Validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41cb152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG ============\n",
      "Missing ratings:\n",
      " UserID       0\n",
      "MovieID      0\n",
      "Rating       0\n",
      "Timestamp    0\n",
      "Datetime     0\n",
      "dtype: int64\n",
      "Missing movies:\n",
      " MovieID     0\n",
      "Title       0\n",
      "Genres     54\n",
      "dtype: int64\n",
      "S·ªë rating ngo√†i [0,10]: 0\n",
      "Duplicate exact (User,Movie,Time): 0\n",
      "Duplicate (User,Movie): 0\n",
      "MovieID trong ratings kh√¥ng c√≥ ·ªü movies: 0\n",
      "Titles nghi l·ªói m√£ h√≥a (mojibake): 1\n",
      "Titles c√≥ k√Ω t·ª± non-ASCII (>0): 2240\n",
      "Genres tr·ªëng/missing: 54\n"
     ]
    }
   ],
   "source": [
    "sec(\"KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG\")\n",
    "\n",
    "# Missing check\n",
    "print(\"Missing ratings:\\n\", ratings.isna().sum())\n",
    "print(\"Missing movies:\\n\", movies.isna().sum())\n",
    "\n",
    "# Out-of-range rating\n",
    "bad_rating = ~ratings[\"Rating\"].between(0,10)\n",
    "print(\"S·ªë rating ngo√†i [0,10]:\", int(bad_rating.sum()))\n",
    "\n",
    "# Duplicates\n",
    "dup_exact = ratings.duplicated(subset=[\"UserID\",\"MovieID\",\"Timestamp\"]).sum()\n",
    "dup_ui = ratings.duplicated(subset=[\"UserID\",\"MovieID\"]).sum()\n",
    "print(\"Duplicate exact (User,Movie,Time):\", int(dup_exact))\n",
    "print(\"Duplicate (User,Movie):\", int(dup_ui))\n",
    "\n",
    "# MovieID integrity\n",
    "unknown_movies = np.setdiff1d(ratings[\"MovieID\"].unique(), movies[\"MovieID\"].unique())\n",
    "print(\"MovieID trong ratings kh√¥ng c√≥ ·ªü movies:\", len(unknown_movies))\n",
    "\n",
    "# Check for mojibake\n",
    "mojibake_patterns = [r\"√É.\", r\"√Ç\", r\"√¢‚Ç¨\", r\"√¢‚Ç¨‚Äú\", r\"√¢‚Ç¨‚Äù\", r\"√¢‚Ç¨‚Ñ¢\", r\"√¢‚Ç¨≈ì\", r\"√¢‚Ç¨¬ù\"]\n",
    "mask_mojibake = movies[\"Title\"].astype(str).str.contains(\"|\".join(mojibake_patterns))\n",
    "print(\"Titles nghi l·ªói m√£ h√≥a (mojibake):\", int(mask_mojibake.sum()))\n",
    "\n",
    "# Non-ASCII ratio\n",
    "def non_ascii_ratio(s): \n",
    "    s = str(s)\n",
    "    return sum(ord(ch) > 127 for ch in s)/max(1,len(s))\n",
    "movies[\"non_ascii_ratio\"] = movies[\"Title\"].apply(non_ascii_ratio)\n",
    "print(\"Titles c√≥ k√Ω t·ª± non-ASCII (>0):\", int((movies[\"non_ascii_ratio\"]>0).sum()))\n",
    "\n",
    "# Genres missing\n",
    "mask_genres_missing = movies[\"Genres\"].isna() | (movies[\"Genres\"].astype(str).str.strip()==\"\")\n",
    "print(\"Genres tr·ªëng/missing:\", int(mask_genres_missing.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd17b4",
   "metadata": {},
   "source": [
    "B·ªô d·ªØ li·ªáu phim t∆∞∆°ng ƒë·ªëi s·∫°ch, ch·ªâ c√≤n 54 d√≤ng b·ªã thi·∫øu tr∆∞·ªùng ‚ÄúGenres‚Äù (th·ªÉ lo·∫°i).\n",
    "=> ƒêi·ªÅn gi√° tr·ªã m·∫∑c ƒë·ªãnh \"Unknown\".\n",
    "\n",
    "Ph√°t hi·ªán 1 ti√™u ƒë·ªÅ phim c√≥ d·∫•u hi·ªáu b·ªã l·ªói m√£ h√≥a k√Ω t·ª± (v√≠ d·ª• ‚ÄúPok√É¬©mon‚Äù thay v√¨ ‚ÄúPok√©mon‚Äù).\n",
    "=> ƒê√¢y l√† h·∫≠u qu·∫£ c·ªßa sai encoding (UTF-8 vs Latin-1) trong d·ªØ li·ªáu g·ªëc.\n",
    "\n",
    "C√≥ 2 240 ti√™u ƒë·ªÅ ch·ª©a k√Ω t·ª± ƒë·∫∑c bi·ªát ngo√†i b·∫£ng ch·ªØ c√°i ASCII c∆° b·∫£n (v√≠ d·ª•: √©, √±, √º, ‚Äô,‚Ä¶).\n",
    "=> ƒêi·ªÅu n√†y ho√†n to√†n b√¨nh th∆∞·ªùng, v√¨ nhi·ªÅu phim c√≥ t√™n ti·∫øng n∆∞·ªõc ngo√†i (Ph√°p, Nh·∫≠t, T√¢y Ban Nha,‚Ä¶). Kh√¥ng c·∫ßn lo·∫°i b·ªè ‚Äî ch·ªâ c·∫ßn ƒë·∫£m b·∫£o x·ª≠ l√Ω Unicode ƒë√∫ng chu·∫©n UTF-8 trong to√†n pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "040e0e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ L√ÄM S·∫†CH D·ªÆ LI·ªÜU ============\n",
      "===> L√†m s·∫°ch ho√†n t·∫•t. S·ªë phim c√≤n l·∫°i: 37944\n"
     ]
    }
   ],
   "source": [
    "sec(\"L√ÄM S·∫†CH D·ªÆ LI·ªÜU\")\n",
    "\n",
    "# 1. S·ª≠a l·ªói m√£ h√≥a th∆∞·ªùng g·∫∑p\n",
    "def fix_mojibake(s):\n",
    "    if not isinstance(s, str): return s\n",
    "    replacements = {\n",
    "        \"Pok√É¬©mon\":\"Pok√©mon\", \"Am√É¬©lie\":\"Am√©lie\", \"Fran√É¬ßais\":\"Fran√ßais\",\n",
    "        \"Se√É¬±or\":\"Se√±or\", \"Jos√É¬©\":\"Jos√©\", \"Beyonc√É¬©\":\"Beyonc√©\"\n",
    "    }\n",
    "    for bad, good in replacements.items(): s = s.replace(bad, good)\n",
    "    return s\n",
    "\n",
    "movies[\"Title\"] = movies[\"Title\"].apply(fix_mojibake)\n",
    "\n",
    "# 2. Chu·∫©n h√≥a Unicode\n",
    "movies[\"Title\"] = movies[\"Title\"].apply(lambda x: unicodedata.normalize(\"NFKC\", x) if isinstance(x,str) else x)\n",
    "\n",
    "# 3. Lo·∫°i k√Ω t·ª± ƒë·∫∑c bi·ªát kh√¥ng c·∫ßn thi·∫øt\n",
    "def clean_text(s):\n",
    "    if not isinstance(s,str): return s\n",
    "    s = re.sub(r\"[^0-9A-Za-z√Ä-·ªπ‚Äô\\'\\-\\.\\,\\!\\?\\:\\;\\(\\)\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "movies[\"Title\"] = movies[\"Title\"].apply(clean_text)\n",
    "\n",
    "# 4. ƒêi·ªÅn Genres thi·∫øu\n",
    "movies[\"Genres\"] = movies[\"Genres\"].fillna(\"Unknown\").replace(\"\", \"Unknown\")\n",
    "\n",
    "# 5. Lo·∫°i duplicate MovieID v√† (Title, Year)\n",
    "def extract_year(title):\n",
    "    if not isinstance(title,str): return np.nan\n",
    "    m = re.search(r\"\\((\\d{4})\\)\\s*$\", title)\n",
    "    return int(m.group(1)) if m else np.nan\n",
    "movies[\"YearFromTitle\"] = movies[\"Title\"].apply(extract_year).astype(\"Int64\")\n",
    "\n",
    "movies = movies.sort_values([\"MovieID\",\"Genres\"], ascending=[True,True])\n",
    "movies = movies.drop_duplicates(subset=[\"MovieID\"], keep=\"last\")\n",
    "movies = movies.drop_duplicates(subset=[\"Title\",\"YearFromTitle\"], keep=\"first\")\n",
    "\n",
    "# 6. Vi·∫øt hoa chu·∫©n\n",
    "movies[\"Title\"] = movies[\"Title\"].str.strip().apply(lambda s: s.title() if isinstance(s,str) else s)\n",
    "\n",
    "# 7. K·∫øt h·ª£p genres list\n",
    "movies[\"GenresList\"] = movies[\"Genres\"].apply(lambda x: [g.strip() for g in str(x).split(\"|\") if g.strip()!=\"\"])\n",
    "\n",
    "print(\"===> L√†m s·∫°ch ho√†n t·∫•t. S·ªë phim c√≤n l·∫°i:\", len(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "475b5dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ ƒê·ªíNG B·ªò H√ìA RATING - MOVIES ============\n",
      "ƒê√£ lo·∫°i 2379 ratings tr·ªè t·ªõi MovieID kh√¥ng t·ªìn t·∫°i\n",
      "Ratings h·ª£p l·ªá: 919019\n",
      "K√≠ch th∆∞·ªõc sau merge: (919019, 9)\n"
     ]
    }
   ],
   "source": [
    "sec(\"ƒê·ªíNG B·ªò H√ìA RATING - MOVIES\")\n",
    "\n",
    "before = len(ratings)\n",
    "ratings = ratings[ratings[\"MovieID\"].isin(movies[\"MovieID\"])]\n",
    "print(f\"ƒê√£ lo·∫°i {before - len(ratings)} ratings tr·ªè t·ªõi MovieID kh√¥ng t·ªìn t·∫°i\")\n",
    "\n",
    "ratings = ratings.dropna(subset=[\"Datetime\"])\n",
    "ratings = ratings[ratings[\"Rating\"].between(0,10)]\n",
    "print(\"Ratings h·ª£p l·ªá:\", len(ratings))\n",
    "\n",
    "data = ratings.merge(\n",
    "    movies[[\"MovieID\",\"Title\",\"Genres\",\"GenresList\",\"YearFromTitle\"]],\n",
    "    on=\"MovieID\", how=\"left\"\n",
    ")\n",
    "print(\"K√≠ch th∆∞·ªõc sau merge:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088a606",
   "metadata": {},
   "source": [
    "before = len(ratings) l∆∞u l·∫°i s·ªë d√≤ng ban ƒë·∫ßu c·ªßa b·∫£ng ratings.\n",
    "\n",
    "ratings[\"MovieID\"].isin(movies[\"MovieID\"]):\n",
    "Ki·ªÉm tra xem MovieID trong b·∫£ng ratings c√≥ t·ªìn t·∫°i trong b·∫£ng movies kh√¥ng.\n",
    "\n",
    "Ch·ªâ gi·ªØ l·∫°i nh·ªØng d√≤ng h·ª£p l·ªá (MovieID c√≥ trong danh s√°ch phim).\n",
    "\n",
    "N·∫øu ratings ch·ª©a ƒë√°nh gi√° cho phim kh√¥ng c√≥ th√¥ng tin trong b·∫£ng movies (g·ªçi l√† orphan ratings), ta lo·∫°i b·ªè ch√∫ng.\n",
    "\n",
    "üìò V√≠ d·ª•:\n",
    "N·∫øu c√≥ MovieID = 999999 trong ratings m√† kh√¥ng c√≥ trong movies, th√¨ d√≤ng ƒë√≥ b·ªã lo·∫°i."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c7af1c",
   "metadata": {},
   "source": [
    "dropna(subset=[\"Datetime\"])\n",
    "‚Üí B·ªè c√°c d√≤ng b·ªã thi·∫øu gi√° tr·ªã th·ªùi gian (Datetime).\n",
    "V√¨ ta c·∫ßn timestamp cho chia temporal split, n√™n kh√¥ng th·ªÉ gi·ªØ d√≤ng n√†o kh√¥ng c√≥ th·ªùi gian.\n",
    "\n",
    "ratings[\"Rating\"].between(0,10)\n",
    "‚Üí L·ªçc ch·ªâ gi·ªØ c√°c gi√° tr·ªã trong kho·∫£ng [0,10].\n",
    "(Tr√°nh tr∆∞·ªùng h·ª£p d·ªØ li·ªáu b·ªã l·ªói, v√≠ d·ª• ƒëi·ªÉm -1 ho·∫∑c 15.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1725c1",
   "metadata": {},
   "source": [
    "M·ª•c ti√™u: G·ªôp th√¥ng tin t·ª´ b·∫£ng movies (m√¥ t·∫£ phim) v√†o b·∫£ng ratings (h√†nh vi ng∆∞·ªùi d√πng).\n",
    "\n",
    "on=\"MovieID\": n·ªëi hai b·∫£ng d·ª±a tr√™n kh√≥a chung l√† MovieID.\n",
    "\n",
    "how=\"left\": gi·ªØ t·∫•t c·∫£ c√°c d√≤ng c·ªßa ratings,\n",
    "n·∫øu phim n√†o c√≥ th√¥ng tin th√¨ th√™m c·ªôt Title, Genres, GenresList, YearFromTitle;\n",
    "n·∫øu kh√¥ng c√≥ (r·∫•t hi·∫øm) th√¨ ƒëi·ªÅn NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e047c77",
   "metadata": {},
   "source": [
    "B·∫£ng data l√† t·∫≠p d·ªØ li·ªáu t·ªïng h·ª£p ho√†n ch·ªânh ‚Äî ch·ª©a c·∫£ th√¥ng tin h√†nh vi (UserID, Rating, Datetime) v√† th√¥ng tin n·ªôi dung (Title, Genres, Year).\n",
    "ƒê√¢y ch√≠nh l√† ƒë·∫ßu v√†o cu·ªëi c√πng cho c√°c m√¥ h√¨nh g·ª£i √Ω, ƒë·∫∑c bi·ªát l√† m√¥ h√¨nh Hybrid Recommender System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53129a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ TEMPORAL CROSS-VALIDATION (PER-USER) ============\n",
      "Fold 1: Train=655319 | Test=263700 | Ratio=0.7\n",
      "Fold 2: Train=698450 | Test=220569 | Ratio=0.75\n",
      "Fold 3: Train=741040 | Test=177979 | Ratio=0.8\n"
     ]
    }
   ],
   "source": [
    "sec(\"TEMPORAL CROSS-VALIDATION (PER-USER)\")\n",
    "\n",
    "data = data.sort_values([\"UserID\",\"Datetime\"]) #S·∫Øp x·∫øp d·ªØ li·ªáu theo ng∆∞·ªùi d√πng v√† th·ªùi gian\n",
    "folds = {} #Kh·ªüi t·∫°o bi·∫øn ch·ª©a k·∫øt qu·∫£\n",
    "\n",
    "for fold, ratio in enumerate(TRAIN_RATIOS, start=1): #Duy·ªát qua danh s√°ch TRAIN_RATIOS = [0.7, 0.75, 0.8]\n",
    "    train_parts, test_parts = [], []\n",
    "    for uid, grp in data.groupby(\"UserID\", sort=False): \n",
    "#groupby(\"UserID\") gom t·∫•t c·∫£ c√°c rating c·ªßa t·ª´ng user v√†o nh√≥m (grp).\n",
    "#Duy·ªát qua t·ª´ng user ƒë·ªÉ chia ri√™ng l·∫ª ‚Äî ƒë√¢y ch√≠nh l√† ph·∫ßn ‚Äúper-user‚Äù trong Temporal CV.\n",
    "        n = len(grp)\n",
    "        if n < MIN_USER_INTERACTIONS:\n",
    "            train_parts.append(grp)\n",
    "            continue\n",
    "#ƒê·∫øm s·ªë l∆∞·ª£ng rating c·ªßa user (n).\n",
    "#N·∫øu √≠t h∆°n ng∆∞·ª°ng t·ªëi thi·ªÉu MIN_USER_INTERACTIONS = 5 ‚Üí kh√¥ng t√°ch test, v√¨ test s·∫Ω r·ªóng ho·∫∑c qu√° √≠t ‚Üí gi·ªØ to√†n b·ªô v√†o train.\n",
    "#‚öôÔ∏èL√Ω do: tr√°nh test r·ªóng cho user √≠t ho·∫°t ƒë·ªông.\n",
    "        split_idx = int(np.floor(ratio * n))\n",
    "        split_idx = min(max(1, split_idx), n-1)\n",
    "        train_parts.append(grp.iloc[:split_idx])\n",
    "        test_parts.append(grp.iloc[split_idx:])\n",
    "    train = pd.concat(train_parts, ignore_index=True)\n",
    "    test  = pd.concat(test_parts, ignore_index=True)\n",
    "    folds[f\"Fold_{fold}\"] = {\"train\":train, \"test\":test}\n",
    "    print(f\"Fold {fold}: Train={len(train)} | Test={len(test)} | Ratio={ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf4a9b",
   "metadata": {},
   "source": [
    "split_idx: v·ªã tr√≠ c·∫Øt gi·ªØa train v√† test (theo th·ª© t·ª± th·ªùi gian).\n",
    "V√≠ d·ª•: n·∫øu user c√≥ 10 rating, ratio=0.8 ‚Üí split_idx = 8.\n",
    "‚Üí Train: 8 d√≤ng ƒë·∫ßu, Test: 2 d√≤ng cu·ªëi.\n",
    "min(max(1, split_idx), n-1) b·∫£o ƒë·∫£m:\n",
    "C√≥ √≠t nh·∫•t 1 d√≤ng train, √≠t nh·∫•t 1 d√≤ng test (kh√¥ng b·ªã tr·ªëng)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75504c8f",
   "metadata": {},
   "source": [
    "B·ªô d·ªØ li·ªáu v·∫´n l√† m·ªôt t·∫≠p duy nh·∫•t (921 398 rating).\n",
    "\n",
    "Ba fold ch·ªâ chia kh√°c nhau theo th·ªùi gian ‚Äì t·ª©c l√† m√¥ ph·ªèng vi·ªác h·ªá th·ªëng ƒë∆∞·ª£c ‚Äúc·∫≠p nh·∫≠t‚Äù qua c√°c m·ªëc th·ªùi gian kh√°c nhau.\n",
    "\n",
    "Trong Temporal Cross-Validation per-user, vi·ªác tƒÉng t·ªâ l·ªá hu·∫•n luy·ªán (t·ª´ 70%, 75% ƒë·∫øn 80%) kh√¥ng ph·∫£i l√† th√™m d·ªØ li·ªáu m·ªõi, m√† l√† thay ƒë·ªïi ranh gi·ªõi th·ªùi gian gi·ªØa qu√° kh·ª© v√† t∆∞∆°ng lai.\n",
    "\n",
    "ƒêi·ªÅu n√†y gi√∫p m√¥ ph·ªèng k·ªãch b·∫£n h·ªá th·ªëng g·ª£i √Ω ƒë∆∞·ª£c hu·∫•n luy·ªán l·∫°i sau m·ªôt th·ªùi gian ho·∫°t ƒë·ªông, khi c√≥ th√™m c√°c t∆∞∆°ng t√°c l·ªãch s·ª≠ c·ªßa ng∆∞·ªùi d√πng.\n",
    "\n",
    "Nh∆∞ v·∫≠y, m·∫∑c d√π t·∫≠p d·ªØ li·ªáu g·ªëc kh√¥ng thay ƒë·ªïi, m·ªói fold v·∫´n ƒë·∫°i di·ªán cho m·ªôt giai ƒëo·∫°n ph√°t tri·ªÉn kh√°c nhau c·ªßa h·ªá th·ªëng theo tr·ª•c th·ªùi gian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e16a73",
   "metadata": {},
   "source": [
    "‚Üí Sau khi hu·∫•n luy·ªán & ƒë√°nh gi√° 3 fold, m√†y s·∫Ω c√≥ 3 b·ªô k·∫øt qu·∫£ (RMSE, Precision@K,‚Ä¶).\n",
    "T·ª´ ƒë√≥:\n",
    "\n",
    "- T√≠nh trung b√¨nh v√† ƒë·ªô l·ªách chu·∫©n ‚Üí ƒë·ªô ·ªïn ƒë·ªãnh c·ªßa m√¥ h√¨nh.\n",
    "\n",
    "- V·∫Ω bi·ªÉu ƒë·ªì hi·ªáu nƒÉng theo t·ªâ l·ªá train ‚Üí xu h∆∞·ªõng h·ªçc theo th·ªùi gian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27bc1f1",
   "metadata": {},
   "source": [
    "Fold 1 (70/30):\n",
    "- Train = 655 319\n",
    "- Test = 263 700\n",
    "\n",
    "=> T·ªïng c·ªông ‚âà 919 019 (do m·ªôt v√†i user <5 rating ƒë∆∞·ª£c gi·ªØ to√†n b·ªô trong train, n√™n t·ªïng h∆°i l·ªách ch√∫t)\n",
    "\n",
    "Train chi·∫øm ~70% d·ªØ li·ªáu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d1af359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ T·ªîNG K·∫æT CU·ªêI ============\n",
      "n_users: 71648\n",
      "n_movies: 37944\n",
      "n_ratings: 919019\n",
      "n_folds: 3\n",
      "Fold 1: train=655319, test=263700, unique_users=71648\n",
      "Fold 2: train=698450, test=220569, unique_users=71648\n",
      "Fold 3: train=741040, test=177979, unique_users=71648\n"
     ]
    }
   ],
   "source": [
    "sec(\"T·ªîNG K·∫æT CU·ªêI\")\n",
    "\n",
    "summary = {\n",
    "    \"n_users\": data[\"UserID\"].nunique(),\n",
    "    \"n_movies\": data[\"MovieID\"].nunique(),\n",
    "    \"n_ratings\": len(data),\n",
    "    \"n_folds\": len(folds),\n",
    "}\n",
    "for k,v in summary.items(): print(f\"{k}: {v}\")\n",
    "\n",
    "for i,(name,fold) in enumerate(folds.items(),start=1):\n",
    "    print(f\"Fold {i}: train={len(fold['train'])}, test={len(fold['test'])}, \"\n",
    "          f\"unique_users={fold['train']['UserID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f0c91",
   "metadata": {},
   "source": [
    "√ù nghƒ©a h·ªçc thu·∫≠t:\n",
    "\n",
    "- M·ªói fold c√≥ c√πng s·ªë l∆∞·ª£ng ng∆∞·ªùi d√πng (71 707), nghƒ©a l√† t·∫•t c·∫£ user ƒë·ªÅu c√≥ d·ªØ li·ªáu hu·∫•n luy·ªán ‚Äî r·∫•t t·ªët, kh√¥ng b·ªã cold-start.\n",
    "\n",
    "- Train tƒÉng d·∫ßn, test gi·∫£m d·∫ßn ƒë√∫ng logic 70/30 ‚Üí 80/20.\n",
    "\n",
    "- T·ªïng s·ªë rating gi·ªØa train + test ‚âà t·ªïng g·ªëc (ƒë·∫£m b·∫£o kh√¥ng m·∫•t m√°t d·ªØ li·ªáu)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651d87d9",
   "metadata": {},
   "source": [
    "T·∫°i sao temporal per-user split gi√∫p tr√°nh cold-start?\n",
    "User n√†o c√≥ <5 rating ‚Üí ƒë∆∞·ª£c gi·ªØ to√†n b·ªô trong train, kh√¥ng c√≥ test.\n",
    "\n",
    "User n√†o ƒë·ªß rating ‚Üí chia theo th·ªùi gian, n√™n c·∫£ train v√† test ƒë·ªÅu thu·ªôc c√πng m·ªôt user.\n",
    "\n",
    "K·∫øt qu·∫£:\n",
    "\n",
    "- Kh√¥ng c√≥ user m·ªõi trong test ‚Üí tr√°nh ƒë∆∞·ª£c user cold-start.\n",
    "\n",
    "- M·ªói user ƒë√£ c√≥ √≠t nh·∫•t v√†i d√≤ng rating trong train ‚Üí m√¥ h√¨nh ƒë√£ ‚Äúbi·∫øt‚Äù h·ªç.\n",
    "\n",
    "- T∆∞∆°ng t·ª±, m·ªói movie trong test ƒë·ªÅu t·ªìn t·∫°i trong train ‚Üí tr√°nh item cold-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b683494b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Fold_1: 0 user m·ªõi, 5466 phim m·ªõi\n",
      "Fold Fold_2: 0 user m·ªõi, 4481 phim m·ªõi\n",
      "Fold Fold_3: 0 user m·ªõi, 3488 phim m·ªõi\n"
     ]
    }
   ],
   "source": [
    "#Ki·ªÉm tra cold-start\n",
    "# Ki·ªÉm tra user ho·∫∑c movie trong test m√† kh√¥ng c√≥ trong train\n",
    "for i, fold in folds.items():\n",
    "    cold_users = np.setdiff1d(fold['test']['UserID'].unique(),\n",
    "                              fold['train']['UserID'].unique())\n",
    "    cold_movies = np.setdiff1d(fold['test']['MovieID'].unique(),\n",
    "                               fold['train']['MovieID'].unique())\n",
    "    print(f\"Fold {i}: {len(cold_users)} user m·ªõi, {len(cold_movies)} phim m·ªõi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fc13f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u checkpoint th√†nh c√¥ng t·∫°i: C:\\Users\\ADMIN\\Documents\\Kh√≥a lu·∫≠n\\MovieTweetings Dataset\\data\\processed\\20251102-161934\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# üîí L∆ØU CHECKPOINT D·ªÆ LI·ªÜU SAU X·ª¨ L√ù\n",
    "# =========================================\n",
    "import time, json\n",
    "from pathlib import Path\n",
    "\n",
    "# üïí 1. T·∫°o th∆∞ m·ª•c version (theo ng√†y gi·ªù ƒë·ªÉ tr√°nh ghi ƒë√®)\n",
    "version = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "base_dir = Path(f\"data/processed/{version}\")\n",
    "base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# üíæ 2. L∆∞u b·∫£ng d·ªØ li·ªáu ƒë√£ clean & merge cu·ªëi c√πng\n",
    "data.to_parquet(base_dir / \"data_clean.parquet\", index=False)\n",
    "\n",
    "# üíæ 3. L∆∞u t·ª´ng fold (train/test)\n",
    "for i, (name, fold) in enumerate(folds.items(), start=1):\n",
    "    fold[\"train\"].to_parquet(base_dir / f\"fold{i}_train.parquet\", index=False)\n",
    "    fold[\"test\"].to_parquet(base_dir / f\"fold{i}_test.parquet\", index=False)\n",
    "\n",
    "# üß† 4. L∆∞u metadata (th√¥ng tin c·∫•u h√¨nh & k√≠ch th∆∞·ªõc)\n",
    "meta = {\n",
    "    \"version\": version,\n",
    "    \"n_users\": int(data[\"UserID\"].nunique()),\n",
    "    \"n_movies\": int(data[\"MovieID\"].nunique()),\n",
    "    \"n_ratings\": int(len(data)),\n",
    "    \"time_min\": str(data[\"Datetime\"].min()),\n",
    "    \"time_max\": str(data[\"Datetime\"].max()),\n",
    "    \"train_ratios\": TRAIN_RATIOS,\n",
    "    \"min_user_interactions\": MIN_USER_INTERACTIONS,\n",
    "}\n",
    "with open(base_dir / \"meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u checkpoint th√†nh c√¥ng t·∫°i: {base_dir.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
